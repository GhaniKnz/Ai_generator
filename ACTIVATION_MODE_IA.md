# Guide d'Activation du Mode IA R√©el

## Vue d'Ensemble

Le syst√®me a √©t√© mis √† jour pour utiliser de vrais mod√®les d'IA (Stable Diffusion) au lieu de la g√©n√©ration simul√©e. Les images g√©n√©r√©es seront maintenant de vraies cr√©ations d'IA bas√©es sur vos prompts.

## Configuration Requise

### Mat√©riel Recommand√©
- **GPU NVIDIA** avec au moins 6 GB de VRAM (recommand√© pour performance)
- **RAM**: Minimum 16 GB
- **Espace Disque**: Au moins 10 GB pour les mod√®les

### Mat√©riel Minimum (CPU)
- Le syst√®me peut fonctionner sur CPU mais sera **beaucoup plus lent**
- **RAM**: Minimum 8 GB
- Temps de g√©n√©ration: 2-5 minutes par image au lieu de quelques secondes

## Installation

### √âtape 1: Installer les D√©pendances IA

```bash
# Activer l'environnement virtuel
source .venv/bin/activate  # Linux/Mac
# ou .venv\Scripts\activate  # Windows

# Installer PyTorch (choisir la version selon votre syst√®me)

# Pour GPU NVIDIA (CUDA):
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# Pour CPU uniquement:
pip install torch torchvision

# Installer les biblioth√®ques de diffusion
pip install diffusers transformers accelerate peft safetensors

# Installer les utilitaires
pip install compel opencv-python imageio imageio-ffmpeg

# OU installer tout depuis requirements.txt:
pip install -r requirements.txt
```

### √âtape 2: V√©rifier l'Installation

```bash
python3 -c "import torch; print('CUDA disponible:', torch.cuda.is_available()); print('Device:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU')"
```

R√©sultat attendu:
- Avec GPU: `CUDA disponible: True` + nom de votre GPU
- Sans GPU: `CUDA disponible: False` + `Device: CPU`

### √âtape 3: Configuration (Optionnel)

Cr√©er un fichier `.env` √† la racine du projet:

```bash
# Active le mode IA r√©el (True par d√©faut)
USE_REAL_AI=true

# R√©pertoire pour mettre en cache les mod√®les t√©l√©charg√©s
MODELS_CACHE_DIR=./models_cache
```

### √âtape 4: Premier D√©marrage

Au premier lancement, le syst√®me t√©l√©chargera automatiquement les mod√®les Stable Diffusion (~4-5 GB). Cela peut prendre 10-30 minutes selon votre connexion.

```bash
# D√©marrer le backend
uvicorn app.main:app --reload --port 8000

# Le premier message de g√©n√©ration d√©clenchera le t√©l√©chargement
# Surveillez les logs: "Downloading model..."
```

## Utilisation

### G√©n√©ration d'Images

1. Allez sur `http://localhost:3000/text-to-image`
2. Entrez votre prompt (description de l'image souhait√©e)
3. S√©lectionnez le mod√®le (stable-diffusion-1.5 recommand√© pour commencer)
4. Choisissez le nombre d'images (1-8)
5. Cliquez sur "G√©n√©rer des Images"
6. **Premi√®re g√©n√©ration**: Attendez 10-30 minutes (t√©l√©chargement du mod√®le)
7. **G√©n√©rations suivantes**: 5-30 secondes selon votre GPU

### Exemples de Prompts

**Bon prompts (d√©taill√©s):**
```
"A majestic lion with a golden mane, standing on a rocky cliff at sunset, photorealistic, 4k, highly detailed"

"A futuristic cyberpunk city at night, neon lights, flying cars, rain-soaked streets, cinematic lighting"

"A cozy cottage in a magical forest, mushrooms, fireflies, fantasy art style, vibrant colors"
```

**Prompts √† √©viter (trop vagues):**
```
"un chat"  # Trop simple
"quelque chose de beau"  # Pas assez pr√©cis
```

### Param√®tres Recommand√©s

| Param√®tre | Valeur Recommand√©e | Description |
|-----------|-------------------|-------------|
| **Steps** | 30-50 | Plus = meilleure qualit√© mais plus lent |
| **CFG Scale** | 7-9 | Comment strictement suivre le prompt |
| **Width/Height** | 512x512 | Plus petit = plus rapide |
| **Nombre d'images** | 1-2 | Pour tester rapidement |

### Pour GPU Faible (< 6 GB VRAM)

Si vous rencontrez des erreurs de m√©moire:

1. R√©duisez la r√©solution: 512x512 ou m√™me 384x384
2. G√©n√©rez 1 image √† la fois
3. R√©duisez le nombre de steps √† 20-30

## Mod√®les Disponibles

### Mod√®les Pr√©-install√©s

1. **stable-diffusion-1.5** (Recommand√© pour commencer)
   - Mod√®le: runwayml/stable-diffusion-v1-5
   - Taille: ~4 GB
   - Rapide et fiable

2. **stable-diffusion-xl** (SDXL)
   - Mod√®le: stabilityai/stable-diffusion-xl-base-1.0
   - Taille: ~6.9 GB
   - Meilleure qualit√© mais plus lent
   - N√©cessite plus de VRAM

### Mod√®les Personnalis√©s

Vos mod√®les entra√Æn√©s (LoRA) appara√Ætront automatiquement dans la liste apr√®s l'entra√Ænement.

## D√©pannage

### Probl√®me: "CUDA out of memory"

**Solution:**
- R√©duire la r√©solution de l'image
- G√©n√©rer moins d'images √† la fois
- Fermer les autres applications utilisant le GPU
- Ajouter dans le code (ai_generator.py):
  ```python
  pipeline.enable_sequential_cpu_offload()
  ```

### Probl√®me: "Model download is very slow"

**Solution:**
- V√©rifier votre connexion Internet
- Le t√©l√©chargement ne se fait qu'une fois
- Les mod√®les sont mis en cache dans `./models_cache`

### Probl√®me: "Generation is too slow on CPU"

**Solution:**
- C'est normal sur CPU (2-5 minutes par image)
- Consid√©rer:
  - R√©duire steps √† 20
  - Utiliser r√©solution 384x384
  - G√©n√©rer 1 image √† la fois
  - Ou investir dans un GPU

### Probl√®me: "Images are blurry or low quality"

**Solution:**
- Augmenter le nombre de steps (50-100)
- Utiliser un prompt plus d√©taill√©
- Augmenter CFG Scale (7.5-9)
- Essayer SDXL pour meilleure qualit√©

## Basculer entre Mode R√©el et Mode Mock

Pour revenir au mode simulation (utile pour les tests):

**Option 1: Fichier .env**
```bash
USE_REAL_AI=false
```

**Option 2: Code**
Dans `app/config.py`:
```python
use_real_ai: bool = Field(default=False)  # Changer True -> False
```

Red√©marrer le serveur apr√®s modification.

## Performance Attendue

### Avec GPU NVIDIA (6+ GB VRAM)
- Premi√®re image: 10-30 min (t√©l√©chargement)
- Images suivantes: 5-15 secondes
- 4 images: 20-60 secondes

### Sans GPU (CPU)
- Premi√®re image: 10-30 min (t√©l√©chargement)
- Images suivantes: 2-5 minutes **par image**
- 4 images: 8-20 minutes

## Ressources Suppl√©mentaires

- **Hugging Face Models**: https://huggingface.co/models?pipeline_tag=text-to-image
- **Diffusers Documentation**: https://huggingface.co/docs/diffusers
- **Stable Diffusion Guide**: https://stable-diffusion-art.com/

## Support

Si vous rencontrez des probl√®mes:

1. V√©rifiez les logs du serveur backend
2. V√©rifiez que PyTorch d√©tecte votre GPU: `torch.cuda.is_available()`
3. V√©rifiez l'espace disque disponible (mod√®les = ~10 GB)
4. Consultez les messages d'erreur dans la console

---

**Le mode IA r√©el est maintenant activ√© par d√©faut!** üé®‚ú®

Testez avec un prompt simple comme: "A beautiful sunset over mountains, oil painting style"
